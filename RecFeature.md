# ArgoPrep Recommendation Feature

## 1) Introduction

The Recommendation Feature is designed to enhance the personalized learning experience on the ArgoPrep platform by providing tailored content recommendations based on user interactions and performance metrics. My role focuses on the backend processes that aggregate, clean, and preprocess data from various services, making it consumable for the Python team to develop and train machine learning models. This feature ensures data accuracy, scalability, and maintainability by leveraging microservices, caching mechanisms, and real-time data streaming.

---

## 2) Project Architecture

### Microservices

1. **User Activity Service**  
   Captures all user interactions across the platform, such as quiz attempts, video plays, and page views.
2. **Content Aggregation Service**  
   Aggregates metadata from various sources, deduplicates entries, and groups data into meaningful categories.

3. **Data Aggregator Service**  
   Consolidates raw and processed data, applies transformations, and provides it to the Python team for training models.

4. **Recommendation API Service**  
   Exposes APIs to the frontend for fetching recommendations processed by the Python team's models.

5. **Logging and Monitoring Service**  
   Tracks API interactions, logs errors, and integrates with Splunk for detailed analytics.

---

## 3) Data Flow

1. **User Activity Capture**  
   User interactions are logged in real-time and published to Kafka for asynchronous processing.

2. **Data Aggregation**  
   The Content Aggregation and Data Aggregator services collect and preprocess data, ensuring accuracy and relevance.

3. **Model Data Preparation**  
   Cleaned and transformed data is provided to the Python team’s training pipeline through REST APIs.

4. **Recommendation Delivery**  
   Processed recommendations from the Python team’s model are stored in Redis for fast retrieval by the frontend.

---

# 4) Detailed Endpoints

## 4.1 User Activity Service

#### Endpoint: `POST /activity`

Captures user interactions like video views, quiz attempts, and page visits.

```java
@PostMapping("/activity")
@PreAuthorize("hasRole('ROLE_USER')")
public ResponseEntity<String> logUserActivity(
    @RequestBody UserActivityRequest request,
    @AuthenticationPrincipal KeycloakPrincipal principal) {

    String userId = principal.getName();

    // Validate request
    if (request.getActivityType() == null || request.getContentId() == null) {
        throw new BadRequestException("Activity type and content ID are required.");
    }

    // Log user activity
    userActivityService.logActivity(userId, request);

    // Publish event to Kafka
    kafkaTemplate.send("user-activity-stream", request);

    return ResponseEntity.ok("Activity logged successfully.");
}
```

## 4.2 Content Aggregation Service

#### Endpoint: `GET /content/aggregate`

Fetches metadata, deduplicates data, and groups it by category.

```java
@GetMapping("/content/aggregate")
@PreAuthorize("hasRole('ROLE_ADMIN')")
public ResponseEntity<List<ContentMetadata>> aggregateContent(
    @RequestParam(required = false) String category,
    @RequestParam(required = false) int maxResults) {

    // Fetch content
    List<ContentMetadata> aggregatedData = contentService.fetchAggregatedContent(category, maxResults);

    // Deduplication
    Set<String> uniqueContentIds = new HashSet<>();
    aggregatedData.removeIf(content -> !uniqueContentIds.add(content.getContentId()));

    // Grouping by category
    Map<String, List<ContentMetadata>> groupedData = aggregatedData.stream()
        .collect(Collectors.groupingBy(ContentMetadata::getCategory));

    return ResponseEntity.ok(aggregatedData);
}
```

## 4.3 Data Aggregator Service

#### Endpoint: `GET /data/training`

Prepares and provides aggregated data for the Python team to train models.

```java
@GetMapping("/data/training")
@PreAuthorize("hasRole('ROLE_ADMIN')")
public ResponseEntity<List<TrainingData>> fetchTrainingData(
    @RequestParam(required = false) String dateRange,
    @RequestParam(required = false) String filterBy) {

    // Fetch and transform data
    List<TrainingData> data = dataAggregatorService.fetchData(dateRange, filterBy);

    // Apply preprocessing
    data.forEach(item -> {
        item.setNormalizedScore(normalizeScore(item.getRawScore()));
        item.setProcessedTimestamp(Instant.now());
    });

    return ResponseEntity.ok(data);
}
```

## 4.4 Recommendation API Service

#### Endpoint: `GET /recommendations/{userId}`

Fetches recommendations generated by the Python model for a specific user.

```java
@GetMapping("/recommendations/{userId}")
@PreAuthorize("hasRole('ROLE_USER')")
public ResponseEntity<List<Recommendation>> getRecommendations(
    @PathVariable String userId,
    @AuthenticationPrincipal KeycloakPrincipal principal) {

    if (!userId.equals(principal.getName())) {
        throw new UnauthorizedAccessException("Access denied.");
    }

    // Fetch recommendations from Redis cache
    List<Recommendation> recommendations = recommendationService.fetchCachedRecommendations(userId);

    return ResponseEntity.ok(recommendations);
}
```

## 4.5 Logging and Monitoring Service

#### Endpoint: `GET /logs/errors`

Fetches error logs for administrators.

```java
@GetMapping("/logs/errors")
@PreAuthorize("hasRole('ROLE_ADMIN')")
public ResponseEntity<List<ErrorLog>> getErrorLogs(
    @RequestParam(required = false) String dateRange) {

    List<ErrorLog> logs = loggingService.fetchErrorLogs(dateRange);

    return ResponseEntity.ok(logs);
}
```

## 5) Key Aggregation and Transformation Techniques

### Deduplication

Duplicates are removed using a `HashSet` of unique identifiers. For example:

- In the **Content Aggregation Service**, duplicate content IDs are eliminated.

### Normalization

Scores or metrics are normalized to a standard range (e.g., 0-1) before being sent to the Python team.

### Grouping

Data is grouped by categories such as content type or engagement metrics using `Collectors.groupingBy()`.

### Filtering

Data is filtered based on parameters like:

- Date range
- User preferences
- Content type  
  before being sent to the Python team.

---

## 6) Keycloak Integration

### Roles

- **`ROLE_USER`**: Regular users accessing personalized recommendations.
- **`ROLE_ADMIN`**: Administrators managing content and accessing logs.

### Configuration

Keycloak is used for:

- **OAuth 2.0 Token Generation**: Secure user authentication.
- **Role-Based Access Control**: Ensures secure API interactions.
- **Inter-Service Authentication**: Facilitates secure communication between microservices.

---

## 7) Use of CI/CD Pipeline in the ArgoPrep Project

### I. Version Control System

- We used **CodeCommit** to manage and track changes in the codebase.
- Hosted on **AWS**, this version control system allowed us to:
  - Create commits for incremental changes.
  - Utilize branches to develop new features or resolve bugs without affecting the main branch.

## II. Continuous Integration Tools

- We utilized **Jenkins** as our CI/CD tool to automate testing, building, and merging code.
- The pipeline was managed using a `Jenkinsfile`, enabling a consistent and maintainable workflow.

## III. Build Automation

- For every code commit, Jenkins initiated:
  - Code compilation and testing using **Maven**, tailored for our Java-based microservices.
  - Static code analysis to ensure adherence to best practices.
  - Dependency management to handle third-party libraries used across ArgoPrep's tech stack.

## IV. Artifact Repository

- The output of successful builds, such as JAR files for Spring Boot microservices, was stored in S3.
- This ensured easy access to different versions of the application artifacts for rollback or deployment purposes.

## V. Continuous Deployment

- **Containerization:** Applications were containerized using **Docker** to encapsulate dependencies and ensure consistent behavior across environments.
- **Orchestration:** Containers were deployed and managed using **Kubernetes**, enabling:
  - Load balancing.
  - Scalability.
  - Automatic failover.
- **Deployment Strategies:** Deployment techniques such as **blue-green deployments** were used to ensure seamless feature rollouts with minimal disruption.

---

# Data Layer / Schemas

## Database Systems

- We used **MySQL** as our primary database for microservices.
- Planned migration of some services to **MongoDB** for flexibility with hierarchical data.

## Key Tables and Fields

### Users Table

- `user_id` (Primary Key)
- `username`
- `email`
- `role` (e.g., student, teacher, admin)
- `created_at`
- `last_login`
- `status` (e.g., active, suspended)

### Quiz Attempts Table

- `attempt_id` (Primary Key)
- `user_id` (Foreign Key)
- `quiz_id` (Foreign Key)
- `score`
- `date_attempted`
- `time_taken`
- `questions_attempted` (JSON or array to track performance by question)

### Subscription Plans Table

- `plan_id` (Primary Key)
- `user_id` (Foreign Key)
- `plan_type` (e.g., monthly, annual)
- `start_date`
- `end_date`
- `status` (e.g., active, expired)

### Learning Progress Table

- `progress_id` (Primary Key)
- `user_id` (Foreign Key)
- `module_id` (Foreign Key)
- `completion_status` (e.g., in progress, completed)
- `time_spent`
- `last_accessed`

### Feedback and Ratings Table

- `feedback_id` (Primary Key)
- `user_id` (Foreign Key)
- `course_id` (Foreign Key)
- `rating` (e.g., 1-5 stars)
- `comments`
- `submitted_at`

---

# REST APIs

## User Management Service

1. `GET /users/all` - Retrieves all users.
2. `POST /users/authenticate` - Authenticates user login.
3. `PUT /users/{userId}/password` - Updates a user's password.
4. `GET /users/{userId}/status` - Checks the status of a user's account.

## Quiz Service

1. `GET /quiz/all` - Retrieves all quizzes.
2. `POST /quiz/submit` - Submits quiz responses for a user.
3. `GET /quiz/stats` - Retrieves quiz performance statistics.

## Reports Service

1. `GET /reports/{userId}` - Fetches all progress reports for a user.
2. `POST /reports/generate` - Generates a new progress report.
3. `PUT /reports/{reportId}` - Updates a specific report.
4. `DELETE /reports/{reportId}` - Deletes a specific report.
5. `GET /reports/{reportId}` - Retrieves a specific report.
6. `POST /reports/batch` - Generates reports for multiple users.
7. `GET /reports/stats` - Provides statistics on generated reports.
8. `PUT /reports/{reportId}/send` - Sends a report to a specified recipient.

---

## Summary

This implementation includes my participation in this Recommendation Feature. By providing clean, aggregated, and preprocessed data to the Python and analytics team, I enable them to build effective machine learning models. I provided:

- Advanced data transformation
- Secure API design
- Real-time data processing using Kafka and Redis
